import faiss
import numpy as np
import json
import os
import re
import google.generativeai as genai
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import random


# --- Ø¥Ø¹Ø¯Ø§Ø¯ Google Gemini ---
genai.configure(api_key="AIzaSyDhV5xCVB_u0XJTPMuQmbEjymBtepUZtpI")
EMBEDDING_MODEL = "models/text-embedding-004"

# --- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
with open("C:\\Users\\Mandoo\\Desktop\\Faiss_Gemini_Chatbot2\\hist.json", "r", encoding="utf-8") as file:
    data = json.load(file)

# --- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯Ø±ÙˆØ³ ---
def extract_lessons(data):
    lessons = []
    for chapter in data["chapters"]:
        for lesson in chapter["lessons"]:
            lessons.append({
                "id": f"{chapter['chapter_number']}-{lesson['lesson_number']}",
                "title": lesson["title"],
                "content": lesson["content"]
            })
    return lessons

lessons = extract_lessons(data)

# --- Ø¥Ù†Ø´Ø§Ø¡ Embedding ---
def generate_embedding(text):
    response = genai.embed_content(model=EMBEDDING_MODEL, content=text, task_type="retrieval_document")
    return np.array(response["embedding"], dtype=np.float32)

# --- Ø¥Ø¹Ø¯Ø§Ø¯ FAISS ---
dimension = 768
index = None
lesson_ids = []
lesson_texts = []

def build_faiss_index():
    global index, lesson_ids, lesson_texts

    if os.path.exists("faiss_index.bin"):
        print("ğŸ“‚ Loading existing FAISS index...")
        index, lesson_ids, lesson_texts = load_faiss_index()
        return

    print("ğŸ›  Building FAISS index...")
    index = faiss.IndexFlatL2(dimension)
    lesson_vectors = []

    for lesson in lessons:
        embedding = generate_embedding(lesson["content"])
        lesson_vectors.append(embedding)
        lesson_ids.append(lesson["id"])
        lesson_texts.append(lesson["content"])

    lesson_vectors = np.array(lesson_vectors, dtype=np.float32)
    faiss.normalize_L2(lesson_vectors)
    index.add(lesson_vectors)

    faiss.write_index(index, "faiss_index.bin")
    with open("lesson_ids.json", "w", encoding="utf-8") as f:
        json.dump({"lesson_ids": lesson_ids, "lesson_texts": lesson_texts}, f, ensure_ascii=False)

    print(f"âœ… FAISS index built and saved with {len(lesson_ids)} lessons!")

def load_faiss_index():
    index = faiss.read_index("faiss_index.bin")
    with open("lesson_ids.json", "r", encoding="utf-8") as f:
        data = json.load(f)
    return index, data["lesson_ids"], data["lesson_texts"]

# --- Ø§Ù„Ø¨Ø­Ø« ---
def search_lessons(query, top_k=5):
    global index, lesson_ids, lesson_texts
    if index is None:
        index, lesson_ids, lesson_texts = load_faiss_index()

    query_embedding = generate_embedding(query).reshape(1, -1)
    faiss.normalize_L2(query_embedding)

    distances, indices = index.search(query_embedding, top_k)
    results = [lesson_texts[i] for i in indices[0] if i < len(lesson_texts)]

    if not results:
        return ["Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© Ø­ÙˆÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ØŒ Ù„ÙƒÙ† ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø£Ùˆ ØªÙˆØ¶ÙŠØ­Ù‡."]

    return results

def is_mcq(question: str) -> bool:
    return bool(re.search(r"[Ø£-ÙŠ]\-", question)) or "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©" in question or "Ø§Ø®ØªØ±" in question


def extract_final_answer(response: str):
    match = re.search(r"Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©\s+Ø§Ù„ØµØ­ÙŠØ­Ø©\s*[:ï¼š]?\s*\(?([Ø£Ø¨Ø¬Ø¯])\)?", response)
    return match.group(1) if match else None

def generate_response(question, context):
    import random, re
    context_text = "\n\n".join(context) if isinstance(context, list) else context

    greetings = [
        "Ø£ÙƒÙŠØ¯ ÙŠØ§ Ø¨Ø·Ù„! ğŸ’ª Ø¥Ù„ÙŠÙƒ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø³Ø·:",
        "Ø¨ÙƒÙ„ Ø³Ø±ÙˆØ±ØŒ Ù‡Ø°Ø§ Ù…Ø§ ÙˆØ¬Ø¯ØªÙ‡ Ù„Ùƒ ğŸ˜Š",
        "Ø¯Ø¹Ù†ÙŠ Ø£ÙˆØ¶Ø­ Ù„Ùƒ ÙƒØ£Ù†Ù†Ø§ ÙÙŠ Ø§Ù„Ø­ØµØ© ğŸ‘‡",
        "Ø³Ø¹ÙŠØ¯ Ø¨Ø³Ø¤Ø§Ù„Ùƒ! ÙˆÙ‡Ù†Ø§ Ø§Ù„Ø´Ø±Ø­ Ø¨Ø§Ù„ØªÙØµÙŠÙ„:"
    ]
    closings = [
        "\nÙ‡Ù„ Ù„Ø¯ÙŠÙƒ Ø³Ø¤Ø§Ù„ Ø¢Ø®Ø±ØŸ ğŸ¤—",
        "\nØ¨Ø¥Ù…ÙƒØ§Ù†Ùƒ ØªØ³Ø£Ù„ Ø¹Ù† Ø£ÙŠ Ø¯Ø±Ø³ ØªØ­Ø¨! ğŸ“˜",
        "\nÙ„Ø§ ØªØªØ±Ø¯Ø¯ ØªØ³Ø£Ù„Ù†ÙŠ Ø£ÙŠ ÙˆÙ‚Øª ğŸ˜‰"
    ]

    if is_mcq(question):
        prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù„Ø·Ù„Ø§Ø¨ Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© ÙÙŠ Ù…ØµØ±.
Ø£Ø¬Ø¨ Ø¹Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ø¬Ø§Ø¨Ø© ØªÙØµÙŠÙ„ÙŠØ© ØªØ´Ø±Ø­ ÙÙ‚Ø· Ù„Ù…Ø§Ø°Ø§ Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„ØµØ­ÙŠØ­ Ù‡Ùˆ Ø§Ù„Ø£Ù†Ø³Ø¨.
Ù„Ø§ ØªØ°ÙƒØ± Ø£Ùˆ ØªØ­Ù„Ù„ Ø¨Ù‚ÙŠØ© Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±Ø§Øª Ø£Ø¨Ø¯Ù‹Ø§.
ÙˆÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø¥Ø¬Ø§Ø¨ØªÙƒØŒ Ø§ÙƒØªØ¨ ÙÙŠ Ø³Ø·Ø± Ù…Ù†ÙØµÙ„:
Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©: (Ø£ / Ø¨ / Ø¬ / Ø¯)

Ø§Ù„Ø³Ø¤Ø§Ù„: {question}
Ø§Ù„Ù…ØµØ§Ø¯Ø±:
{context_text}"""
    else:
        prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù„Ø·Ù„Ø§Ø¨ Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© ÙÙŠ Ù…ØµØ±.
Ø£Ø¬Ø¨ Ø¹Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø¨Ø³Ø·Ø© ÙˆØ´Ø§Ù…Ù„Ø© ØªØ³Ø§Ø¹Ø¯ Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¹Ù„Ù‰ Ø§Ù„ÙÙ‡Ù… Ø§Ù„Ø¬ÙŠØ¯.
Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… ØªÙ†Ø³ÙŠÙ‚ Ø£Ø³Ø¦Ù„Ø© Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† Ù…ØªØ¹Ø¯Ø¯ØŒ ÙˆÙ„Ø§ ØªØ°ÙƒØ± Ø£ÙŠ Ø¥Ø¬Ø§Ø¨Ø© ØµØ­ÙŠØ­Ø© Ø¹Ù„Ù‰ Ø´ÙƒÙ„ (Ø£ / Ø¨ / Ø¬ / Ø¯).
Ø§ÙƒØªÙÙ Ø¨Ø´Ø±Ø­ Ù…ÙØµÙ„ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø³Ø¤Ø§Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ø±.

Ø§Ù„Ø³Ø¤Ø§Ù„: {question}
Ø§Ù„Ù…ØµØ§Ø¯Ø±:
{context_text}"""

    # Call Gemini
    model = genai.GenerativeModel("gemini-2.5-flash-preview-05-20")
    response = model.generate_content(prompt).text.strip()

    # Enforce clean ending for MCQ
    if is_mcq(question):
        final_letter = extract_final_answer(response)
        if not final_letter:
            # Try to guess last option mentioned in text (usually the correct one)
            fallback_match = re.findall(r"\b[Ø£Ø¨Ø¬Ø¯]\b", response)
            if fallback_match:
                guessed = fallback_match[-1]
                response += f"\nØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©: {guessed}"
            else:
                response += "\nØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©: ØºÙŠØ± Ù…Ø­Ø¯Ø¯Ø©"
    else:
        # Remove any hallucinated MCQ-like endings
        response = re.sub(r"\bØ§Ù„Ø¥Ø¬Ø§Ø¨Ø©\s+Ø§Ù„ØµØ­ÙŠØ­Ø©\s*[:ï¼š]?\s*\(?[Ø£Ø¨Ø¬Ø¯]?\)?", "", response)
        response = re.sub(r"\n+Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©.*$", "", response, flags=re.MULTILINE)
        response = re.sub(r"\n{2,}", "\n\n", response).strip()

    # Final wrapping
    final_response = f"{random.choice(greetings)}\n\n{response}\n\n{random.choice(closings)}"
    return final_response


# --- Flask API ---
app = Flask(__name__, static_folder="static", template_folder="templates")
CORS(app, resources={r"/ask": {"origins": "*"}})

@app.route("/")
def index():
    return render_template("index.html")

@app.route("/ask", methods=["POST"])
def ask():
    data = request.get_json()
    question = data.get("question", "").strip()
    if not question:
        return jsonify({"error": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø·Ù„ÙˆØ¨"}), 400

    related_lessons = search_lessons(question)
    response = generate_response(question, related_lessons)
    return jsonify({"answer": response})

if __name__ == "__main__":
    build_faiss_index()
    app.run(debug=True)
